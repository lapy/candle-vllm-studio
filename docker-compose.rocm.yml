version: '3.8'

services:
  candle-vllm-studio:
    build:
      context: .
      args:
        BASE_IMAGE: rocm/dev-ubuntu-22.04:5.7-complete
    image: candle-vllm-studio:rocm
    ports:
      - "41234:8080"
    volumes:
      - ./data:/app/data
      - ./backend:/app/backend
      - ./frontend:/app/frontend
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    environment:
      - CUDA_VISIBLE_DEVICES=""
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - RELOAD=true
      - HIP_VISIBLE_DEVICES=all
      - ROC_ENABLE_PRE_VEGA=1
      # - HSA_OVERRIDE_GFX_VERSION=10.3.0
      # - HUGGINGFACE_API_KEY=your_hf_token_here
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    privileged: true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
    cap_add:
      - SYS_ADMIN
    shm_size: '2gb'

